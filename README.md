机器学习核心算法概览
===================

*****************

*## KNN算法————不学习我也能预测<br>
KNN学习算法可以说是机器学习众多算法里最简单的一个算法，它的思想非常简单，因此初学者必须要了解。



*## 逻辑回归（LR）————算法工程师必考
也许你觉得逻辑回归在研究生实验室里基本上派不上用场，那就说明LR无用武之地，那你就错了。LR在工业<br>
界是最常使用的一种算法，尤其是在大数据环境下更是如此。因为LR算法具有模型简单存储方便，计算复杂<br>
度低等诸多优势。



*## Naive Bayes算法————后验概率学习算法
朴素贝叶斯算法的核心是利用贝叶斯后验概率进行学习的算法，理论简单，实现简单，假设（特征完全独立<br>
性）更简单，但是朴素贝叶斯算法在文本分类等领域的应用也是十分广泛的。



*## 决策树算法————IF-THEN 规则的集合
可以毫不夸张地说，决策树是机器学习中最重要最常用的的一类算法。它们理论完美精妙，并且多棵决策树<br>
可以通过不同的组合方法结合在一起成为集成学习方法中的弱学习器。无论是工业界还是学术界，应用都十<br>
分范。

## XGBoost——基于决策树的 Kaggle 夺冠利器 
无需多言，XGBoost 是 kaggle 比赛中打拼出来的算法。坊间也有一句名言：在 Kaggle 比赛的算法选择<br>
中，结构化数据用 XGBoost，非结构化数据用深度学习。

从这句话可以看出 XGBoost 的江湖地位。当然，它是靠优秀的计算效率和准确率以及对分布式大数据的支<br>
持才获得如此的成绩的，XGBoost 算法应该是初学者必懂算法。

## LightGBM——据说这家伙比 XGBoost 还牛 
鉴于 XGBoost 的火爆程度，微软 MSRA 决定要开发出一种算法系统来挑战 XGBoost 的江湖地位，于是LightGBM<br>
应运而生。

LightGBM 是在 XGBoost 算法存在不足之上进行深度优化的提升树算法：它具有更低的内存占用，更高的时间效率<br>
，并且精度也略高于 XGBoost，为此，LightGBM 与 XGBoost 对比学习，应该是初学者提升基本功的一次饕餮盛宴。

## 无监督聚类——从 K-Means 说起
机器学习最主要的两大类算法就是有监督学习和无监督学习。本节几乎将无监督算法主要算法及其原理详细介绍了一遍，<br>
从 K-Means 到密度聚类的 DBSCAN，再到层次聚类的 AGENS，并且全都通过伪代码的形式给出了算法执行步骤，加深<br>
读者对无监督学习算法的理解。

## Isolation Forest——异常检测的利器 
在异常检测领域，Isolation Forest 独树一帜。本文主要介绍一种由南大周志华老师团队提出的 IForest 异常检测<br>
算法

## 神经网络——深度学习的基础
学习机器学习，尤其是近年来深度学习的火爆。神经网络绝对不能够错过，它是深度学习的基础，是连接机器学习和深度<br>
学习的桥梁。

本节作者不仅介绍了神经网络的工作原理，并且以 Sigmoid 函数为激活函数为例，详细推导了 BP 学习算法的数学原理。<br>
使得读者对神经网络算法不仅能够知其然，而且能够做到知其所以然。

## 特征降维——PCA 与 LDA 
在数据量大，特征维度高的时候，我们需要在原始信息损失可接受范围内适当降低特征维度以减少算法对内存的大量占用。<br>
在此基础上，我们详细介绍了PCA与LDA算法各自降维的原理，并最终使用实战案例程序直观地显示两种算法降维的效果。
